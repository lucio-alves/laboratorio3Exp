"""
An√°lise Completa dos Datasets de Pull Requests do GitHub
========================================================

Script final para an√°lise dos datasets dataset.csv e dataset_completo.csv
com tratamento robusto de erros e gr√°ficos comparativos.
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from pathlib import Path
import warnings

warnings.filterwarnings('ignore')
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")

class DatasetAnalyzer:
    def __init__(self, filename):
        self.filename = filename
        self.df = None
        self.stats = {}
        
    def load_data(self):
        """Carrega dados com tratamento robusto de erros"""
        try:
            print(f"üìä Carregando {self.filename}...")
            
            # Tentar diferentes encodings
            for encoding in ['utf-8', 'latin-1', 'cp1252']:
                try:
                    self.df = pd.read_csv(self.filename, encoding=encoding)
                    break
                except UnicodeDecodeError:
                    continue
            
            if self.df is None:
                print(f"‚ùå N√£o foi poss√≠vel carregar {self.filename}")
                return False
            
            # Normalizar colunas baseado no tipo de dataset
            self._normalize_columns()
            
            # Calcular estat√≠sticas
            self._calculate_stats()
            
            print(f"‚úÖ {self.filename}: {len(self.df):,} PRs de {self.df['repo'].nunique()} reposit√≥rios")
            return True
            
        except Exception as e:
            print(f"‚ùå Erro ao carregar {self.filename}: {e}")
            return False
    
    def _normalize_columns(self):
        """Normaliza colunas para formato padr√£o"""
        # Mapear colunas do dataset completo se necess√°rio
        column_mapping = {
            'repo_full_name': 'repo',
            'author': 'autor', 
            'review_duration_hours': 'tempo_analise_horas',
            'changed_files': 'num_files',
            'description_length': 'descricao_len',
            'comments_count': 'num_comentarios',
            'participants_count': 'num_participants'
        }
        
        for old_col, new_col in column_mapping.items():
            if old_col in self.df.columns and new_col not in self.df.columns:
                self.df[new_col] = self.df[old_col]
        
        # Criar colunas ausentes com valores padr√£o
        if 'num_review_comments' not in self.df.columns:
            self.df['num_review_comments'] = 0
        
        if 'state' not in self.df.columns:
            if 'merged' in self.df.columns:
                self.df['state'] = self.df['merged'].apply(lambda x: 'merged' if x else 'closed')
            else:
                self.df['state'] = 'closed'
        
        # Garantir colunas num√©ricas
        numeric_cols = ['tempo_analise_horas', 'num_files', 'additions', 'deletions', 'num_participants', 'num_comentarios']
        for col in numeric_cols:
            if col in self.df.columns:
                self.df[col] = pd.to_numeric(self.df[col], errors='coerce')
        
        # Criar tamanho total
        if 'additions' in self.df.columns and 'deletions' in self.df.columns:
            self.df['tamanho_total'] = self.df['additions'].fillna(0) + self.df['deletions'].fillna(0)
        else:
            self.df['tamanho_total'] = 0
        
        # Limpar dados ausentes em colunas essenciais
        essential_cols = ['tempo_analise_horas', 'num_files', 'repo', 'autor']
        existing_cols = [col for col in essential_cols if col in self.df.columns]
        if existing_cols:
            self.df = self.df.dropna(subset=existing_cols)
    
    def _calculate_stats(self):
        """Calcula estat√≠sticas do dataset"""
        self.stats = {
            'total_prs': len(self.df),
            'repositorios': self.df['repo'].nunique() if 'repo' in self.df.columns else 0,
            'autores': self.df['autor'].nunique() if 'autor' in self.df.columns else 0,
            'tempo_medio': self.df['tempo_analise_horas'].mean() if 'tempo_analise_horas' in self.df.columns else 0,
            'mediana_arquivos': self.df['num_files'].median() if 'num_files' in self.df.columns else 0,
            'total_linhas': self.df['tamanho_total'].sum() if 'tamanho_total' in self.df.columns else 0
        }
    
    def print_summary(self):
        """Imprime resumo do dataset"""
        print(f"\nüìà RESUMO - {self.filename}")
        print("=" * 50)
        print(f"‚Ä¢ Total de PRs: {self.stats['total_prs']:,}")
        print(f"‚Ä¢ Reposit√≥rios √∫nicos: {self.stats['repositorios']}")
        print(f"‚Ä¢ Autores √∫nicos: {self.stats['autores']:,}")
        print(f"‚Ä¢ Tempo m√©dio an√°lise: {self.stats['tempo_medio']:.1f} horas")
        print(f"‚Ä¢ Mediana arquivos/PR: {self.stats['mediana_arquivos']:.0f}")
        print(f"‚Ä¢ Total linhas modificadas: {self.stats['total_linhas']:,}")
    
    def generate_plots(self, output_dir):
        """Gera todos os gr√°ficos para o dataset"""
        if self.df is None or len(self.df) == 0:
            print(f"‚ö†Ô∏è Sem dados v√°lidos para {self.filename}")
            return False
        
        dataset_name = self.filename.replace('.csv', '')
        
        try:
            # 1. Arquivos vs Tempo
            self._plot_arquivos_vs_tempo(output_dir, dataset_name)
            
            # 2. Tamanho vs Tempo  
            self._plot_tamanho_vs_tempo(output_dir, dataset_name)
            
            # 3. Top Autores
            self._plot_top_autores(output_dir, dataset_name)
            
            # 4. Distribui√ß√£o Repos
            self._plot_distribuicao_repos(output_dir, dataset_name)
            
            # 5. Estados PRs (se aplic√°vel)
            if 'state' in self.df.columns:
                self._plot_estados_prs(output_dir, dataset_name)
            
            # 6. Participa√ß√£o
            if 'num_participants' in self.df.columns:
                self._plot_participacao(output_dir, dataset_name)
            
            # 7. Coment√°rios vs Tempo
            if 'num_comentarios' in self.df.columns:
                self._plot_comentarios_vs_tempo(output_dir, dataset_name)
            
            return True
            
        except Exception as e:
            print(f"‚ùå Erro ao gerar gr√°ficos para {self.filename}: {e}")
            return False
    
    def _plot_arquivos_vs_tempo(self, output_dir, dataset_name):
        """Gr√°fico: Arquivos vs Tempo"""
        plt.figure(figsize=(12, 8))
        
        # Filtrar outliers
        q99_files = self.df['num_files'].quantile(0.99)
        q99_time = self.df['tempo_analise_horas'].quantile(0.99)
        
        df_filtered = self.df[
            (self.df['num_files'] <= q99_files) & 
            (self.df['tempo_analise_horas'] <= q99_time)
        ]
        
        plt.scatter(df_filtered['num_files'], df_filtered['tempo_analise_horas'],
                   alpha=0.6, s=50, c='#2E86AB', edgecolors='white', linewidth=0.5)
        
        # Tend√™ncia
        if len(df_filtered) > 1:
            z = np.polyfit(df_filtered['num_files'], df_filtered['tempo_analise_horas'], 1)
            p = np.poly1d(z)
            plt.plot(df_filtered['num_files'], p(df_filtered['num_files']), 
                     color='#F18F01', linewidth=2, linestyle='--', label='Tend√™ncia')
            plt.legend()
        
        plt.xlabel('N√∫mero de Arquivos Modificados', fontweight='bold')
        plt.ylabel('Tempo de An√°lise (horas)', fontweight='bold')
        plt.title(f'Rela√ß√£o: Arquivos √ó Tempo de An√°lise\n{dataset_name} ({len(df_filtered):,} PRs)', 
                 fontweight='bold')
        
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        
        filename = output_dir / f'arquivos_vs_tempo_{dataset_name}.png'
        plt.savefig(filename, dpi=300, bbox_inches='tight')
        plt.close()
        print(f"üíæ {filename.name}")
    
    def _plot_tamanho_vs_tempo(self, output_dir, dataset_name):
        """Gr√°fico: Tamanho vs Tempo"""
        plt.figure(figsize=(12, 8))
        
        # Filtrar outliers
        q95_size = self.df['tamanho_total'].quantile(0.95)
        q95_time = self.df['tempo_analise_horas'].quantile(0.95)
        
        df_filtered = self.df[
            (self.df['tamanho_total'] <= q95_size) & 
            (self.df['tempo_analise_horas'] <= q95_time) &
            (self.df['tamanho_total'] > 0)
        ]
        
        if len(df_filtered) > 0:
            color_col = 'num_participants' if 'num_participants' in df_filtered.columns else None
            
            if color_col and df_filtered[color_col].nunique() > 1:
                scatter = plt.scatter(df_filtered['tamanho_total'], 
                                     df_filtered['tempo_analise_horas'],
                                     c=df_filtered[color_col], cmap='viridis',
                                     alpha=0.7, s=60, edgecolors='white', linewidth=0.5)
                plt.colorbar(scatter, label='Participantes')
            else:
                plt.scatter(df_filtered['tamanho_total'], 
                           df_filtered['tempo_analise_horas'],
                           alpha=0.7, s=60, c='#A23B72',
                           edgecolors='white', linewidth=0.5)
        
        plt.xlabel('Total de Linhas Modificadas', fontweight='bold')
        plt.ylabel('Tempo de An√°lise (horas)', fontweight='bold') 
        plt.title(f'Rela√ß√£o: Tamanho √ó Tempo de An√°lise\n{dataset_name} ({len(df_filtered):,} PRs)', 
                 fontweight='bold')
        
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        
        filename = output_dir / f'tamanho_vs_tempo_{dataset_name}.png'
        plt.savefig(filename, dpi=300, bbox_inches='tight')
        plt.close()
        print(f"üíæ {filename.name}")
    
    def _plot_top_autores(self, output_dir, dataset_name):
        """Gr√°fico: Top Autores"""
        plt.figure(figsize=(15, 10))
        
        author_counts = self.df['autor'].value_counts().head(20)
        
        bars = plt.barh(range(len(author_counts)), author_counts.values, 
                       color=sns.color_palette("viridis", len(author_counts)))
        
        plt.yticks(range(len(author_counts)), author_counts.index, fontsize=10)
        plt.xlabel('N√∫mero de Pull Requests', fontweight='bold')
        plt.title(f'Top 20 Autores com Mais PRs\n{dataset_name} (Total: {len(self.df):,} PRs)', 
                 fontweight='bold')
        
        # Valores nas barras
        for i, (bar, value) in enumerate(zip(bars, author_counts.values)):
            plt.text(value + max(author_counts.values) * 0.01, i, str(value), 
                    va='center', ha='left', fontweight='bold', fontsize=9)
        
        plt.grid(axis='x', alpha=0.3)
        plt.tight_layout()
        
        filename = output_dir / f'top_autores_{dataset_name}.png'
        plt.savefig(filename, dpi=300, bbox_inches='tight')
        plt.close()
        print(f"üíæ {filename.name}")
    
    def _plot_distribuicao_repos(self, output_dir, dataset_name):
        """Gr√°fico: Distribui√ß√£o Repos"""
        plt.figure(figsize=(15, 8))
        
        repo_counts = self.df['repo'].value_counts().head(15)
        
        bars = plt.bar(range(len(repo_counts)), repo_counts.values,
                      color=sns.color_palette("Set2", len(repo_counts)))
        
        # Nomes dos repos (s√≥ a parte final)
        repo_names = [repo.split('/')[-1] if '/' in repo else repo for repo in repo_counts.index]
        plt.xticks(range(len(repo_counts)), repo_names, rotation=45, ha='right')
        
        plt.ylabel('N√∫mero de Pull Requests', fontweight='bold')
        plt.title(f'Top 15 Reposit√≥rios por PRs\n{dataset_name}', fontweight='bold')
        
        # Valores nas barras
        for bar, value in zip(bars, repo_counts.values):
            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(repo_counts.values) * 0.01, 
                    str(value), ha='center', va='bottom', fontweight='bold', fontsize=9)
        
        plt.grid(axis='y', alpha=0.3)
        plt.tight_layout()
        
        filename = output_dir / f'distribuicao_repos_{dataset_name}.png'
        plt.savefig(filename, dpi=300, bbox_inches='tight')
        plt.close()
        print(f"üíæ {filename.name}")
    
    def _plot_estados_prs(self, output_dir, dataset_name):
        """Gr√°fico: Estados PRs"""
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
        
        state_counts = self.df['state'].value_counts()
        colors = ['#C73E1D', '#7209B7', '#F18F01'][:len(state_counts)]
        
        # Pizza
        ax1.pie(state_counts.values, labels=state_counts.index, autopct='%1.1f%%',
                colors=colors, startangle=90)
        ax1.set_title('Distribui√ß√£o de Estados dos PRs', fontweight='bold')
        
        # Tempo por estado
        avg_time = self.df.groupby('state')['tempo_analise_horas'].mean()
        bars = ax2.bar(avg_time.index, avg_time.values, color=colors[:len(avg_time)])
        
        ax2.set_ylabel('Tempo M√©dio de An√°lise (horas)', fontweight='bold')
        ax2.set_title('Tempo M√©dio por Estado', fontweight='bold')
        ax2.grid(axis='y', alpha=0.3)
        
        # Valores
        for bar, value in zip(bars, avg_time.values):
            ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(avg_time.values) * 0.01, 
                    f'{value:.0f}h', ha='center', va='bottom', fontweight='bold')
        
        plt.tight_layout()
        
        filename = output_dir / f'estados_prs_{dataset_name}.png'
        plt.savefig(filename, dpi=300, bbox_inches='tight')
        plt.close()
        print(f"üíæ {filename.name}")
    
    def _plot_participacao(self, output_dir, dataset_name):
        """Gr√°fico: Participa√ß√£o"""
        plt.figure(figsize=(12, 8))
        
        max_participants = int(self.df['num_participants'].max())
        bins = range(0, min(max_participants + 2, 20))  # Limitar bins para evitar gr√°ficos muito largos
        
        plt.hist(self.df['num_participants'], bins=bins,
                alpha=0.7, color='#2E86AB', edgecolor='white', linewidth=0.5)
        
        plt.xlabel('N√∫mero de Participantes por PR', fontweight='bold')
        plt.ylabel('Frequ√™ncia de PRs', fontweight='bold')
        plt.title(f'Distribui√ß√£o de Participa√ß√£o em PRs\n{dataset_name}', fontweight='bold')
        
        # M√©dia
        mean_participants = self.df['num_participants'].mean()
        plt.axvline(mean_participants, color='#F18F01', linestyle='--', linewidth=2,
                   label=f'M√©dia: {mean_participants:.1f}')
        
        plt.legend()
        plt.grid(axis='y', alpha=0.3)
        plt.tight_layout()
        
        filename = output_dir / f'participacao_{dataset_name}.png'
        plt.savefig(filename, dpi=300, bbox_inches='tight')
        plt.close()
        print(f"üíæ {filename.name}")
    
    def _plot_comentarios_vs_tempo(self, output_dir, dataset_name):
        """Gr√°fico: Coment√°rios vs Tempo"""
        plt.figure(figsize=(12, 8))
        
        # Filtrar outliers
        q95_time = self.df['tempo_analise_horas'].quantile(0.95)
        q95_comments = self.df['num_comentarios'].quantile(0.95)
        
        df_filtered = self.df[
            (self.df['tempo_analise_horas'] <= q95_time) &
            (self.df['num_comentarios'] <= q95_comments)
        ]
        
        plt.scatter(df_filtered['num_comentarios'], 
                   df_filtered['tempo_analise_horas'],
                   alpha=0.6, c='#A23B72', s=50,
                   edgecolors='white', linewidth=0.5)
        
        plt.xlabel('N√∫mero de Coment√°rios', fontweight='bold')
        plt.ylabel('Tempo de An√°lise (horas)', fontweight='bold')
        plt.title(f'Rela√ß√£o: Coment√°rios √ó Tempo\n{dataset_name} ({len(df_filtered):,} PRs)', 
                 fontweight='bold')
        
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        
        filename = output_dir / f'comentarios_vs_tempo_{dataset_name}.png'
        plt.savefig(filename, dpi=300, bbox_inches='tight')
        plt.close()
        print(f"üíæ {filename.name}")

def create_comparison_report(analyzers, output_dir):
    """Cria relat√≥rio comparativo"""
    report_file = output_dir / "relatorio_comparativo.md"
    
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write("# Relat√≥rio Comparativo - An√°lise de Pull Requests GitHub\n\n")
        f.write("## Datasets Analisados\n\n")
        
        for analyzer in analyzers:
            f.write(f"### {analyzer.filename}\n")
            f.write(f"- **Total de PRs:** {analyzer.stats['total_prs']:,}\n")
            f.write(f"- **Reposit√≥rios √∫nicos:** {analyzer.stats['repositorios']}\n") 
            f.write(f"- **Autores √∫nicos:** {analyzer.stats['autores']:,}\n")
            f.write(f"- **Tempo m√©dio an√°lise:** {analyzer.stats['tempo_medio']:.1f} horas\n")
            f.write(f"- **Mediana arquivos/PR:** {analyzer.stats['mediana_arquivos']:.0f}\n")
            f.write(f"- **Total linhas modificadas:** {analyzer.stats['total_linhas']:,}\n\n")
        
        # Compara√ß√£o se h√° mais de um dataset
        if len(analyzers) > 1:
            f.write("## Compara√ß√£o entre Datasets\n\n")
            f.write("| M√©trica | Dataset 1 | Dataset 2 | Diferen√ßa |\n")
            f.write("|---------|-----------|-----------|----------|\n")
            
            stats1, stats2 = analyzers[0].stats, analyzers[1].stats
            
            metrics = [
                ('PRs Total', 'total_prs'),
                ('Reposit√≥rios', 'repositorios'), 
                ('Autores', 'autores'),
                ('Tempo M√©dio (h)', 'tempo_medio'),
                ('Linhas Totais', 'total_linhas')
            ]
            
            for label, key in metrics:
                val1, val2 = stats1[key], stats2[key]
                if val1 > 0:
                    diff_pct = ((val2/val1 - 1) * 100)
                    diff_str = f"{diff_pct:+.1f}%"
                else:
                    diff_str = "N/A"
                
                f.write(f"| {label} | {val1:,.0f} | {val2:,.0f} | {diff_str} |\n")
        
        f.write(f"\n## Gr√°ficos Gerados\n\n")
        f.write("Os seguintes gr√°ficos foram gerados para cada dataset:\n\n")
        f.write("1. **Arquivos √ó Tempo de An√°lise** - Scatter plot mostrando correla√ß√£o\n")
        f.write("2. **Tamanho √ó Tempo de An√°lise** - Rela√ß√£o entre linhas modificadas e tempo\n") 
        f.write("3. **Top 20 Autores** - Ranking dos contribuidores mais ativos\n")
        f.write("4. **Distribui√ß√£o por Reposit√≥rio** - PRs por reposit√≥rio\n")
        f.write("5. **Estados dos PRs** - Distribui√ß√£o e tempo m√©dio por estado\n")
        f.write("6. **Participa√ß√£o** - Histograma de participantes por PR\n")
        f.write("7. **Coment√°rios √ó Tempo** - Correla√ß√£o entre coment√°rios e tempo\n\n")
        
        f.write("---\n")
        f.write(f"*Relat√≥rio gerado automaticamente*\n")
    
    print(f"üìã Relat√≥rio salvo: {report_file}")

def main():
    """Fun√ß√£o principal"""
    print("üöÄ AN√ÅLISE COMPLETA DE PULL REQUESTS DO GITHUB")
    print("=" * 60)
    print("Processando datasets dos top 200 reposit√≥rios mais populares\n")
    
    # Datasets dispon√≠veis
    datasets = ["dataset.csv", "dataset_completo.csv"]
    
    # Criar diret√≥rio de sa√≠da
    output_dir = Path("analise_final")
    output_dir.mkdir(exist_ok=True)
    
    analyzers = []
    
    # Processar cada dataset
    for dataset in datasets:
        if Path(dataset).exists():
            print(f"üîç Processando: {dataset}")
            analyzer = DatasetAnalyzer(dataset)
            
            if analyzer.load_data():
                analyzer.print_summary()
                
                print(f"üé® Gerando gr√°ficos para {dataset}...")
                if analyzer.generate_plots(output_dir):
                    analyzers.append(analyzer)
                    print(f"‚úÖ Gr√°ficos conclu√≠dos para {dataset}\n")
                else:
                    print(f"‚ùå Falha ao gerar gr√°ficos para {dataset}\n")
            else:
                print(f"‚ùå Falha ao carregar {dataset}\n")
        else:
            print(f"‚ö†Ô∏è Arquivo n√£o encontrado: {dataset}\n")
    
    # Criar relat√≥rio comparativo
    if analyzers:
        create_comparison_report(analyzers, output_dir)
    
    # Resumo final
    print("üéâ AN√ÅLISE FINALIZADA!")
    print(f"üìÅ Resultados salvos em: {output_dir}/")
    print(f"üìä Datasets processados: {len(analyzers)}")
    
    if analyzers:
        total_prs = sum(a.stats['total_prs'] for a in analyzers)
        total_repos = sum(a.stats['repositorios'] for a in analyzers) 
        print(f"üìà Total geral: {total_prs:,} PRs de {total_repos} reposit√≥rios")
    
    print("\nüí° Abra os arquivos .png para visualizar os gr√°ficos!")

if __name__ == "__main__":
    main()